{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9991,
     "status": "ok",
     "timestamp": 1595702434549,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "g9MnmVN5jNjm",
    "outputId": "e11d107b-8b8e-4eb2-97fe-39d5f1c5cd33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.activations import relu, sigmoid, softmax\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import imgaug.augmenters as iaa\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 412420,
     "status": "ok",
     "timestamp": 1595702854221,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "1jVZ1UMEkKXX"
   },
   "outputs": [],
   "source": [
    "# total number of our output classes: len(char_list)\n",
    "\n",
    "# def batch_generator(img_list,batch_size):\n",
    "#     while True:\n",
    "#         imgs=[]\n",
    "#         ground_truth_txts=[]\n",
    "#         labels=[]\n",
    "#         label_lengths=[]\n",
    "#         input_lengths=[]\n",
    "\n",
    "#         idxs=np.random.randint(0,len(img_list),batch_size)\n",
    "#         for idx in idxs:\n",
    "#             img=cv2.imread('/content/images/'+img_list[idx],0)\n",
    "#             #img=np.expand_dims(img,axis=2)\n",
    "#             img=img/255\n",
    "#             txt=img_list[idx].split('_')[1].split('.')[0]\n",
    "#             imgs.append(preprocess_img(img,(128,32)))\n",
    "#             ground_truth_txts.append(txt)\n",
    "#             labels.append(encode_to_labels(txt))\n",
    "#             input_lengths.append(31)\n",
    "#             label_lengths.append(len(txt))\n",
    "#         imgs=np.expand_dims(imgs,axis=-1)\n",
    "#         labels=pad_sequences(labels, maxlen=max_len, padding='post', value = len(char_list)+1)\n",
    "#         yield [np.array(imgs), np.array(labels), np.array(input_lengths), np.array(label_lengths)],[np.zeros(batch_size)]\n",
    "\n",
    "# def batch_ground_text(img_list,batch_size):\n",
    "#     while True:\n",
    "#         imgs=[]\n",
    "#         ground_truth_txts=[]\n",
    "#         labels=[]\n",
    "#         label_lengths=[]\n",
    "#         input_lengths=[]\n",
    "\n",
    "#         idxs=np.random.randint(0,len(img_list),batch_size)\n",
    "#         for idx in idxs:\n",
    "#             img=cv2.imread('/content/images/'+img_list[idx],0)\n",
    "#             #img=np.expand_dims(img,axis=2)\n",
    "#             img=img/255\n",
    "#             txt=img_list[idx].split('_')[1].split('.')[0]\n",
    "#             imgs.append(preprocess_img(img,(128,32)))\n",
    "#             ground_truth_txts.append(txt)\n",
    "#             labels.append(encode_to_labels(txt))\n",
    "#             input_lengths.append(31)\n",
    "#             label_lengths.append(len(txt))\n",
    "#         imgs=np.expand_dims(imgs,axis=-1)\n",
    "#         labels=pad_sequences(labels, maxlen=max_len, padding='post', value = len(char_list)+1)\n",
    "#         return np.array(imgs),np.array(ground_truth_txts),np.array(labels), np.array(input_lengths), np.array(label_lengths)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "char_list = string.ascii_letters+string.digits+',.?:;'\n",
    " \n",
    "def encode_to_labels(txt):\n",
    "    # encoding each output word into digits\n",
    "    dig_lst = []\n",
    "    for index, char in enumerate(txt):\n",
    "        try:\n",
    "            dig_lst.append(char_list.index(char))\n",
    "        except:\n",
    "            print(char)\n",
    "        \n",
    "    return dig_lst\n",
    "\n",
    "def find_dominant_color(image):\n",
    "        #Resizing parameters\n",
    "        width, height = 150,150\n",
    "        image = image.resize((width, height),resample = 0)\n",
    "        #Get colors from image object\n",
    "        pixels = image.getcolors(width * height)\n",
    "        #Sort them by count number(first element of tuple)\n",
    "        sorted_pixels = sorted(pixels, key=lambda t: t[0])\n",
    "        #Get the most frequent color\n",
    "        dominant_color = sorted_pixels[-1][1]\n",
    "        return dominant_color\n",
    "\n",
    "def preprocess_img(img, imgSize):\n",
    "    \"put img into target img of size imgSize, transpose for TF and normalize gray-values\"\n",
    "\n",
    "    # there are damaged files in IAM dataset - just use black image instead\n",
    "    if img is None:\n",
    "        img = np.zeros([imgSize[1], imgSize[0]]) \n",
    "        print(\"Image None!\")\n",
    "\n",
    "    # create target image and copy sample image into it\n",
    "    (wt, ht) = imgSize\n",
    "    (h, w) = img.shape\n",
    "    fx = w / wt\n",
    "    fy = h / ht\n",
    "    f = max(fx, fy)\n",
    "    newSize = (max(min(wt, int(w / f)), 1),\n",
    "               max(min(ht, int(h / f)), 1))  # scale according to f (result at least 1 and at most wt or ht)\n",
    "    img = cv2.resize(img, newSize, interpolation=cv2.INTER_CUBIC) # INTER_CUBIC interpolation best approximate the pixels image\n",
    "                                                               # see this https://stackoverflow.com/a/57503843/7338066\n",
    "    most_freq_pixel=find_dominant_color(Image.fromarray(img))\n",
    "    target = np.ones([ht, wt]) * most_freq_pixel  \n",
    "    target[0:newSize[1], 0:newSize[0]] = img\n",
    "\n",
    "    img = target\n",
    "\n",
    "    return img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25207,
     "status": "ok",
     "timestamp": 1595702879449,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "_ACXZs0FkOCj"
   },
   "outputs": [],
   "source": [
    "\n",
    "training_img = []\n",
    "training_txt = []\n",
    "train_input_length = []\n",
    "train_label_length = []\n",
    "orig_txt = []\n",
    " \n",
    "#lists for validation dataset\n",
    "valid_img = []\n",
    "valid_txt = []\n",
    "valid_input_length = []\n",
    "valid_label_length = []\n",
    "valid_orig_txt = []\n",
    " \n",
    "max_label_len = 0\n",
    "\n",
    "annot=open('E:/Data generator for CRNN/annotation.txt','r').readlines()\n",
    "imagenames=[]\n",
    "txts=[]\n",
    "\n",
    "for cnt in annot:\n",
    "    filename,txt=cnt.split(',')[0],cnt.split(',')[1].split('\\n')[0]\n",
    "    imagenames.append(filename)\n",
    "    txts.append(txt)\n",
    "    \n",
    "c = list(zip(imagenames, txts))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "imagenames, txts = zip(*c)\n",
    "    \n",
    "\n",
    "    \n",
    "for i in range(len(imagenames)):\n",
    "        img = cv2.imread('E:/Data generator for CRNN/images/'+imagenames[i],0)   \n",
    " \n",
    "        img=preprocess_img(img,(128,32))\n",
    "        img=np.expand_dims(img,axis=-1)\n",
    "        img = img/255.\n",
    "        txt = txts[i]\n",
    "        \n",
    "        # compute maximum length of the text\n",
    "        if len(txt) > max_label_len:\n",
    "            max_label_len = len(txt)\n",
    "            \n",
    "           \n",
    "        # split the 150000 data into validation and training dataset as 10% and 90% respectively\n",
    "        if i%10 == 0:     \n",
    "            valid_orig_txt.append(txt)   \n",
    "            valid_label_length.append(len(txt))\n",
    "            valid_input_length.append(31)\n",
    "            valid_img.append(img)\n",
    "            valid_txt.append(encode_to_labels(txt))\n",
    "        else:\n",
    "            orig_txt.append(txt)   \n",
    "            train_label_length.append(len(txt))\n",
    "            train_input_length.append(31)\n",
    "            training_img.append(img)\n",
    "            training_txt.append(encode_to_labels(txt)) \n",
    "        \n",
    "        # break the loop if total data is 150000\n",
    "        if i == 50000:\n",
    "            flag = 1\n",
    "            break\n",
    "        i+=1\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25206,
     "status": "ok",
     "timestamp": 1595702879455,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "x5eSaZq3lIFm"
   },
   "outputs": [],
   "source": [
    "#pad each output label to maximum text length\n",
    " \n",
    "train_padded_txt = pad_sequences(training_txt, maxlen=max_label_len, padding='post', value = len(char_list))\n",
    "valid_padded_txt = pad_sequences(valid_txt, maxlen=max_label_len, padding='post', value = len(char_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for c in training_txt[0]:\n",
    "#     print(char_list[c],end=\"\")\n",
    "# plt.imshow(training_img[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35275,
     "status": "ok",
     "timestamp": 1595702889538,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "nM3GIraQlf79",
    "outputId": "0016107c-704c-43b2-ff82-b26730365050"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow15\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(32,128,1))\n",
    " \n",
    "# convolution layer with kernel size (3,3)\n",
    "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "# poolig layer with kernel size (2,2)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    " \n",
    "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    " \n",
    "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    " \n",
    "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "# poolig layer with kernel size (2,1)\n",
    "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    " \n",
    "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "# Batch normalization layer\n",
    "batch_norm_5 = BatchNormalization()(conv_5)\n",
    " \n",
    "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = BatchNormalization()(conv_6)\n",
    "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    " \n",
    "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
    " \n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    "\n",
    "# bidirectional LSTM layers with units=128\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    " \n",
    "outputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "# model to be used at test time\n",
    "act_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35256,
     "status": "ok",
     "timestamp": 1595702889540,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "qJ2wnclqljjE",
    "outputId": "20beca32-24a3-4380-9662-dbf136ea925c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 128, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 128, 64)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 32, 256)        295168    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 32, 256)        590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 32, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 32, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 32, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 32, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 32, 512)        2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 32, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 31, 512)        1049088   \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 31, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 31, 256)           656384    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 31, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 31, 68)            17476     \n",
      "=================================================================\n",
      "Total params: 6,620,996\n",
      "Trainable params: 6,618,948\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35242,
     "status": "ok",
     "timestamp": 1595702889543,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "9jFGQFBclwxS",
    "outputId": "697e567f-eb63-4eac-8537-ddd8345a7b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow15\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    " \n",
    " \n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    " \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    " \n",
    " \n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "#model to be used at training time\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35238,
     "status": "ok",
     "timestamp": 1595702889544,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "mCNCgCgkl1Cz"
   },
   "outputs": [],
   "source": [
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
    " \n",
    "filepath=\"best_model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39419,
     "status": "ok",
     "timestamp": 1595702893728,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "mvuZE3wAux_A"
   },
   "outputs": [],
   "source": [
    "training_img = np.array(training_img)\n",
    "train_input_length = np.array(train_input_length)\n",
    "train_label_length = np.array(train_label_length)\n",
    "\n",
    "valid_img = np.array(valid_img)\n",
    "valid_input_length = np.array(valid_input_length)\n",
    "valid_label_length = np.array(valid_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 321671,
     "status": "ok",
     "timestamp": 1595706447509,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "oD74GQJA9rD7",
    "outputId": "e21ef9fe-abe2-47a5-b094-a42cd7abfd26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 45000 samples, validate on 5001 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 458s 10ms/step - loss: 27.2349 - val_loss: 20.3082\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 20.30821, saving model to best_model.hdf5\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 437s 10ms/step - loss: 2.3278 - val_loss: 2.7849\n",
      "\n",
      "Epoch 00002: val_loss improved from 20.30821 to 2.78490, saving model to best_model.hdf5\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 436s 10ms/step - loss: 1.0240 - val_loss: 0.9041\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.78490 to 0.90407, saving model to best_model.hdf5\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 436s 10ms/step - loss: 0.6849 - val_loss: 0.7635\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.90407 to 0.76348, saving model to best_model.hdf5\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 437s 10ms/step - loss: 0.5388 - val_loss: 0.6944\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.76348 to 0.69444, saving model to best_model.hdf5\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 436s 10ms/step - loss: 0.4456 - val_loss: 0.7200\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.69444\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 434s 10ms/step - loss: 0.3844 - val_loss: 0.6322\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.69444 to 0.63220, saving model to best_model.hdf5\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 434s 10ms/step - loss: 0.3357 - val_loss: 0.5664\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.63220 to 0.56638, saving model to best_model.hdf5\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 435s 10ms/step - loss: 0.2834 - val_loss: 0.5221\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.56638 to 0.52207, saving model to best_model.hdf5\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 435s 10ms/step - loss: 0.2688 - val_loss: 0.4193\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52207 to 0.41925, saving model to best_model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1dc8315a5c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs = epochs, validation_data = ([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]), verbose = 1, callbacks = callbacks_list)\n",
    "\n",
    "# model.fit_generator(batch_generator(train_img,256),steps_per_epoch=10000,validation_data=batch_generator(test_img,256),\n",
    "#                     validation_steps=2000,epochs=10,shuffle=True,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fMXRp1Nf1H6"
   },
   "outputs": [],
   "source": [
    "# valid_img,valid_orig_txt, valid_labels, valid_input_length, valid_label_length=batch_ground_text(test_img,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1904,
     "status": "ok",
     "timestamp": 1595704725669,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "Ke-W12wQf7k-",
    "outputId": "8d04f48c-a355-4397-98ae-84247af27aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_text =   xyixenodgxcsi\n",
      "predicted text = xyixenodgxcsi\n",
      "\n",
      "original_text =   wkflxboscqi\n",
      "predicted text = wkflxboscqi\n",
      "\n",
      "original_text =   duzqbj\n",
      "predicted text = duzqbj\n",
      "\n",
      "original_text =   on\n",
      "predicted text = on\n",
      "\n",
      "original_text =   blsoh\n",
      "predicted text = blsoh\n",
      "\n",
      "original_text =   tzkqnasocqqqplymv\n",
      "predicted text = tzkqnasocqqqplymv\n",
      "\n",
      "original_text =   gyndkjymkdcmi\n",
      "predicted text = gyndkjymkdcmi\n",
      "\n",
      "original_text =   tdhkxsfwchbqhynmt\n",
      "predicted text = tdhkxsfwchbqhynmt\n",
      "\n",
      "original_text =   pfkeg\n",
      "predicted text = pfkeg\n",
      "\n",
      "original_text =   qvk\n",
      "predicted text = qvk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the saved best model weights\n",
    "act_model.load_weights('best_model.hdf5')\n",
    " \n",
    "# predict outputs on validation images\n",
    "prediction = act_model.predict(valid_img[10:20])\n",
    " \n",
    "# use CTC decoder\n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                         greedy=True)[0][0])\n",
    " \n",
    "# see the results\n",
    "i = 10\n",
    "for x in out:\n",
    "    print(\"original_text =  \", valid_orig_txt[i])\n",
    "    print(\"predicted text = \", end = '')\n",
    "    for p in x:  \n",
    "        if int(p) != -1:\n",
    "            print(char_list[int(p)], end = '')       \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1842,
     "status": "ok",
     "timestamp": 1595707245763,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "TSSplBFT6p3H"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-814a8eddb417>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/distance.JPG'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m128\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('/content/distance.JPG',0)\n",
    "w, h = img.shape\n",
    "if h > 128 or w > 32:\n",
    "    pass\n",
    "if w < 32:\n",
    "    add_zeros = np.ones((32-w, h))*255\n",
    "    img = np.concatenate((img, add_zeros))\n",
    "\n",
    "if h < 128:\n",
    "    add_zeros = np.ones((32, 128-h))*255\n",
    "    img = np.concatenate((img, add_zeros), axis=1)\n",
    "img = np.expand_dims(img , axis = 2)\n",
    "img=np.expand_dims(img,axis=0)\n",
    "\n",
    "# Normalize each image\n",
    "img = img/255.\n",
    "pred=act_model.predict(img)\n",
    "out = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1],\n",
    "                         greedy=True)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1595707248316,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "dxi1qSk47RJY",
    "outputId": "1146565c-9bd2-41f4-b7c1-eb8e8422a11b"
   },
   "outputs": [],
   "source": [
    "for char in out[0]:\n",
    "  print(char_list[char],end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11345,
     "status": "ok",
     "timestamp": 1595704972392,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "TCvEZ3gzbO8M",
    "outputId": "f53d78cc-4016-42ce-d9dc-0f8edb43812e"
   },
   "outputs": [],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1838,
     "status": "ok",
     "timestamp": 1595705063429,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "I-C4az19bXAq"
   },
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2983,
     "status": "ok",
     "timestamp": 1595705897605,
     "user": {
      "displayName": "socolab org",
      "photoUrl": "",
      "userId": "06470913045262117086"
     },
     "user_tz": -330
    },
    "id": "3NlxG2tCbvpy",
    "outputId": "6aed6f02-19f6-49ce-ce2a-44e4b12da32e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'rather'"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell.correction('rathor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tensorflow15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('./pred_images/distance.JPG',0)\n",
    "\n",
    "w,h=img.shape\n",
    "if h>128 or w>32:\n",
    "    pass\n",
    "if w < 32:\n",
    "    add_zeros = np.ones((32-w, h))*255\n",
    "    img = np.concatenate((img, add_zeros))\n",
    "\n",
    "if h < 128:\n",
    "    add_zeros = np.ones((32, 128-h))*255\n",
    "    img = np.concatenate((img, add_zeros), axis=1)\n",
    "\n",
    "img=np.expand_dims(np.expand_dims(img,axis=0),axis=-1)\n",
    "pred=act_model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del training_img,train_input_length,train_label_length,valid_img,valid_input_length,valid_label_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPcYIy+XUw1gQobR/1x8keW",
   "collapsed_sections": [],
   "name": "CRNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow15",
   "language": "python",
   "name": "tensorflow15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
